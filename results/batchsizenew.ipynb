{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f23bbd-0bfc-44b9-9318-b1c985f28728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.0)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: torch==1.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchsummary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f67203-17a8-4ce2-a0c3-186d9d7baf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c845b04d-0f0a-42b2-8a66-29371aeee9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose device\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0eb9cb-260e-44e2-8f33-6e1fd46a565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "#batch_size=64\n",
    "batch_sizes=[64,128,256]\n",
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a6ec30-adf5-49ad-813b-b61efd8b5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transform\n",
    "train_transform=transforms.Compose(\n",
    "    [transforms.Pad(4),\n",
    "     transforms.RandomCrop(32),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                          std=[0.229,0.224,0.225])])\n",
    "valid_transform=transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                          std=[0.229,0.224,0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73f5b31-d805-4c33-9bb3-c7d42b829630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# download cifar-10 dataset\n",
    "train_dataset=torchvision.datasets.CIFAR10(root='../data/',\n",
    "                                           train=True,\n",
    "                                           transform=train_transform,\n",
    "                                           download=True)\n",
    "test_dataset=torchvision.datasets.CIFAR10(root='../data/',\n",
    "                                           train=False,\n",
    "                                           transform=valid_transform,\n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457ee22c-b7d0-408a-a867-0477f1fcb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data loader\n",
    "#train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "#test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1daf0aa-1c0a-4c88-a130-818f9ef34e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=in_channels,out_channels=out_channels,stride=stride,kernel_size=3,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_channels)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.conv2=nn.Conv2d(in_channels=out_channels,out_channels=out_channels,stride=1,kernel_size=3,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(out_channels)\n",
    "        self.downsample=nn.Sequential()\n",
    "        if (stride!=1) or(in_channels!=out_channels):\n",
    "            self.downsample=nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,out_channels=out_channels,stride=stride,kernel_size=1,bias=False),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "    def forward(self,x):\n",
    "        out=self.conv1(x)\n",
    "        out=self.bn1(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out+=self.downsample(x)\n",
    "        out=self.relu(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66bf687-fa59-4630-befb-ed3dd7a82171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-layer ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,layers,num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels=80                                                  # 64 can be modified\n",
    "        self.conv=nn.Conv2d(in_channels=3,out_channels=80,stride=1,kernel_size=3,padding=1,bias=False)\n",
    "        self.bn=nn.BatchNorm2d(80)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        self.layer1=self.make_layer(block, 80,layers[0], stride=1)        # 64 can be modified\n",
    "        self.layer2=self.make_layer(block, 160, layers[1], stride=2)      # 128 can be modified\n",
    "        self.layer3=self.make_layer(block, 320, layers[2], stride=2)      # 256 can be modified\n",
    "        #self.layer4=self.make_layer(block, 512, layers[3], stride=2)      # 512 can be modified\n",
    "        self.avg_pool=nn.AvgPool2d(8)                                        # 4 can be modified\n",
    "        self.fc=nn.Linear(320,10) \n",
    "        \n",
    "    def make_layer(self,block,out_channels,blocks, stride):\n",
    "        layers=[]\n",
    "        layers.append(block(self.in_channels,out_channels,stride))\n",
    "        self.in_channels=out_channels\n",
    "        for i in range(1,blocks):\n",
    "            layers.append(block(out_channels,out_channels,stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.conv(x)\n",
    "        out=self.bn(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.layer1(out)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        #out=self.layer4(out)\n",
    "        out=self.avg_pool(out)\n",
    "        out=out.view(out.size(0),-1)\n",
    "        out=self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792a9fbd-05dc-4a45-998d-c195827f1266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 80, 32, 32]           2,160\n",
      "       BatchNorm2d-2           [-1, 80, 32, 32]             160\n",
      "              ReLU-3           [-1, 80, 32, 32]               0\n",
      "            Conv2d-4           [-1, 80, 32, 32]          57,600\n",
      "       BatchNorm2d-5           [-1, 80, 32, 32]             160\n",
      "              ReLU-6           [-1, 80, 32, 32]               0\n",
      "            Conv2d-7           [-1, 80, 32, 32]          57,600\n",
      "       BatchNorm2d-8           [-1, 80, 32, 32]             160\n",
      "              ReLU-9           [-1, 80, 32, 32]               0\n",
      "    ResidualBlock-10           [-1, 80, 32, 32]               0\n",
      "           Conv2d-11           [-1, 80, 32, 32]          57,600\n",
      "      BatchNorm2d-12           [-1, 80, 32, 32]             160\n",
      "             ReLU-13           [-1, 80, 32, 32]               0\n",
      "           Conv2d-14           [-1, 80, 32, 32]          57,600\n",
      "      BatchNorm2d-15           [-1, 80, 32, 32]             160\n",
      "             ReLU-16           [-1, 80, 32, 32]               0\n",
      "    ResidualBlock-17           [-1, 80, 32, 32]               0\n",
      "           Conv2d-18           [-1, 80, 32, 32]          57,600\n",
      "      BatchNorm2d-19           [-1, 80, 32, 32]             160\n",
      "             ReLU-20           [-1, 80, 32, 32]               0\n",
      "           Conv2d-21           [-1, 80, 32, 32]          57,600\n",
      "      BatchNorm2d-22           [-1, 80, 32, 32]             160\n",
      "             ReLU-23           [-1, 80, 32, 32]               0\n",
      "    ResidualBlock-24           [-1, 80, 32, 32]               0\n",
      "           Conv2d-25          [-1, 160, 16, 16]         115,200\n",
      "      BatchNorm2d-26          [-1, 160, 16, 16]             320\n",
      "             ReLU-27          [-1, 160, 16, 16]               0\n",
      "           Conv2d-28          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-29          [-1, 160, 16, 16]             320\n",
      "           Conv2d-30          [-1, 160, 16, 16]          12,800\n",
      "      BatchNorm2d-31          [-1, 160, 16, 16]             320\n",
      "             ReLU-32          [-1, 160, 16, 16]               0\n",
      "    ResidualBlock-33          [-1, 160, 16, 16]               0\n",
      "           Conv2d-34          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-35          [-1, 160, 16, 16]             320\n",
      "             ReLU-36          [-1, 160, 16, 16]               0\n",
      "           Conv2d-37          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-38          [-1, 160, 16, 16]             320\n",
      "             ReLU-39          [-1, 160, 16, 16]               0\n",
      "    ResidualBlock-40          [-1, 160, 16, 16]               0\n",
      "           Conv2d-41          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-42          [-1, 160, 16, 16]             320\n",
      "             ReLU-43          [-1, 160, 16, 16]               0\n",
      "           Conv2d-44          [-1, 160, 16, 16]         230,400\n",
      "      BatchNorm2d-45          [-1, 160, 16, 16]             320\n",
      "             ReLU-46          [-1, 160, 16, 16]               0\n",
      "    ResidualBlock-47          [-1, 160, 16, 16]               0\n",
      "           Conv2d-48            [-1, 320, 8, 8]         460,800\n",
      "      BatchNorm2d-49            [-1, 320, 8, 8]             640\n",
      "             ReLU-50            [-1, 320, 8, 8]               0\n",
      "           Conv2d-51            [-1, 320, 8, 8]         921,600\n",
      "      BatchNorm2d-52            [-1, 320, 8, 8]             640\n",
      "           Conv2d-53            [-1, 320, 8, 8]          51,200\n",
      "      BatchNorm2d-54            [-1, 320, 8, 8]             640\n",
      "             ReLU-55            [-1, 320, 8, 8]               0\n",
      "    ResidualBlock-56            [-1, 320, 8, 8]               0\n",
      "           Conv2d-57            [-1, 320, 8, 8]         921,600\n",
      "      BatchNorm2d-58            [-1, 320, 8, 8]             640\n",
      "             ReLU-59            [-1, 320, 8, 8]               0\n",
      "           Conv2d-60            [-1, 320, 8, 8]         921,600\n",
      "      BatchNorm2d-61            [-1, 320, 8, 8]             640\n",
      "             ReLU-62            [-1, 320, 8, 8]               0\n",
      "    ResidualBlock-63            [-1, 320, 8, 8]               0\n",
      "        AvgPool2d-64            [-1, 320, 1, 1]               0\n",
      "           Linear-65                   [-1, 10]           3,210\n",
      "================================================================\n",
      "Total params: 4,914,330\n",
      "Trainable params: 4,914,330\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 24.69\n",
      "Params size (MB): 18.75\n",
      "Estimated Total Size (MB): 43.45\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model=ResNet(ResidualBlock,[3,3,2]).to(device)\n",
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce0c4db-a918-4407-8107-a5d3da54876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99328a9-2e82-4552-92a0-589b5d11d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "def train(model):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    train_acc=0\n",
    "    for img,label in train_loader:\n",
    "        img=img.to(device)\n",
    "        label=label.to(device)\n",
    "        #forward\n",
    "        output=model(img)\n",
    "        loss=criterion(output,label)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #calculate loss and acc\n",
    "        train_loss+=loss.item()\n",
    "        _, predicted=output.max(1)\n",
    "        train_acc+=(predicted==label).sum().item()/len(predicted)\n",
    "    return train_loss/len(train_loader),train_acc/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e59dbe-85a1-411c-a732-f0b4b347e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_acc=0\n",
    "        for img,label in test_loader:\n",
    "            img=img.to(device)\n",
    "            label=label.to(device)\n",
    "            output=model(img)\n",
    "            _, predicted=output.max(1)\n",
    "            valid_acc+=(predicted==label).sum().item()/len(output)\n",
    "    return valid_acc/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8156b-a63d-42f3-9bc9-485b49dd1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 64\n",
      "Epoch 0. Train Loss 1.4893. Train Acc 0.4510. Test Acc 0.5266.\n",
      "Epoch 1. Train Loss 0.9747. Train Acc 0.6540. Test Acc 0.6248.\n",
      "Epoch 2. Train Loss 0.7475. Train Acc 0.7405. Test Acc 0.7687.\n",
      "Epoch 3. Train Loss 0.6366. Train Acc 0.7796. Test Acc 0.7472.\n",
      "Epoch 4. Train Loss 0.5560. Train Acc 0.8098. Test Acc 0.7942.\n",
      "Epoch 5. Train Loss 0.5079. Train Acc 0.8258. Test Acc 0.8187.\n",
      "Epoch 6. Train Loss 0.4647. Train Acc 0.8416. Test Acc 0.7785.\n",
      "Epoch 7. Train Loss 0.4345. Train Acc 0.8500. Test Acc 0.8286.\n",
      "Epoch 8. Train Loss 0.4109. Train Acc 0.8597. Test Acc 0.8166.\n",
      "Epoch 9. Train Loss 0.3892. Train Acc 0.8684. Test Acc 0.8259.\n",
      "Epoch 10. Train Loss 0.3726. Train Acc 0.8721. Test Acc 0.8246.\n",
      "Epoch 11. Train Loss 0.3561. Train Acc 0.8790. Test Acc 0.8371.\n",
      "Epoch 12. Train Loss 0.3439. Train Acc 0.8831. Test Acc 0.8512.\n",
      "Epoch 13. Train Loss 0.3251. Train Acc 0.8897. Test Acc 0.8491.\n",
      "Epoch 14. Train Loss 0.3171. Train Acc 0.8913. Test Acc 0.8451.\n",
      "Epoch 15. Train Loss 0.3032. Train Acc 0.8963. Test Acc 0.8344.\n",
      "Epoch 16. Train Loss 0.2904. Train Acc 0.9016. Test Acc 0.8634.\n",
      "Epoch 17. Train Loss 0.2772. Train Acc 0.9048. Test Acc 0.8551.\n",
      "Epoch 18. Train Loss 0.2684. Train Acc 0.9069. Test Acc 0.8674.\n",
      "Epoch 19. Train Loss 0.2574. Train Acc 0.9129. Test Acc 0.8711.\n",
      "Epoch 20. Train Loss 0.2387. Train Acc 0.9188. Test Acc 0.8704.\n",
      "Epoch 21. Train Loss 0.2301. Train Acc 0.9217. Test Acc 0.8976.\n",
      "Epoch 22. Train Loss 0.2161. Train Acc 0.9278. Test Acc 0.8799.\n",
      "Epoch 23. Train Loss 0.2111. Train Acc 0.9283. Test Acc 0.8819.\n",
      "Epoch 24. Train Loss 0.1987. Train Acc 0.9336. Test Acc 0.8874.\n",
      "Epoch 25. Train Loss 0.1777. Train Acc 0.9402. Test Acc 0.8851.\n",
      "Epoch 26. Train Loss 0.1688. Train Acc 0.9434. Test Acc 0.8823.\n",
      "Epoch 27. Train Loss 0.1537. Train Acc 0.9503. Test Acc 0.8913.\n",
      "Epoch 28. Train Loss 0.1489. Train Acc 0.9508. Test Acc 0.9012.\n",
      "Epoch 29. Train Loss 0.1302. Train Acc 0.9584. Test Acc 0.9156.\n",
      "Epoch 30. Train Loss 0.1228. Train Acc 0.9614. Test Acc 0.9182.\n",
      "Epoch 31. Train Loss 0.1051. Train Acc 0.9664. Test Acc 0.9153.\n",
      "Epoch 32. Train Loss 0.0924. Train Acc 0.9701. Test Acc 0.9169.\n",
      "Epoch 33. Train Loss 0.0795. Train Acc 0.9759. Test Acc 0.9222.\n",
      "Epoch 34. Train Loss 0.0637. Train Acc 0.9815. Test Acc 0.9253.\n",
      "Epoch 35. Train Loss 0.0570. Train Acc 0.9841. Test Acc 0.9322.\n",
      "Epoch 36. Train Loss 0.0436. Train Acc 0.9887. Test Acc 0.9324.\n",
      "Epoch 37. Train Loss 0.0345. Train Acc 0.9920. Test Acc 0.9379.\n",
      "Epoch 38. Train Loss 0.0261. Train Acc 0.9948. Test Acc 0.9408.\n",
      "Epoch 39. Train Loss 0.0203. Train Acc 0.9965. Test Acc 0.9435.\n",
      "Epoch 40. Train Loss 0.0174. Train Acc 0.9975. Test Acc 0.9458.\n",
      "Epoch 41. Train Loss 0.0139. Train Acc 0.9983. Test Acc 0.9474.\n",
      "Epoch 42. Train Loss 0.0116. Train Acc 0.9989. Test Acc 0.9474.\n",
      "Epoch 43. Train Loss 0.0110. Train Acc 0.9990. Test Acc 0.9477.\n",
      "Epoch 44. Train Loss 0.0091. Train Acc 0.9995. Test Acc 0.9475.\n",
      "Epoch 45. Train Loss 0.0088. Train Acc 0.9995. Test Acc 0.9477.\n",
      "Epoch 46. Train Loss 0.0085. Train Acc 0.9997. Test Acc 0.9477.\n",
      "Epoch 47. Train Loss 0.0081. Train Acc 0.9996. Test Acc 0.9483.\n",
      "Epoch 48. Train Loss 0.0081. Train Acc 0.9995. Test Acc 0.9473.\n",
      "Epoch 49. Train Loss 0.0080. Train Acc 0.9996. Test Acc 0.9488.\n",
      "Batch size: 128\n",
      "Epoch 0. Train Loss 1.5845. Train Acc 0.4116. Test Acc 0.4984.\n",
      "Epoch 1. Train Loss 1.0375. Train Acc 0.6270. Test Acc 0.5500.\n",
      "Epoch 2. Train Loss 0.8322. Train Acc 0.7057. Test Acc 0.6689.\n",
      "Epoch 3. Train Loss 0.6854. Train Acc 0.7595. Test Acc 0.6936.\n",
      "Epoch 4. Train Loss 0.5866. Train Acc 0.7980. Test Acc 0.7599.\n",
      "Epoch 5. Train Loss 0.5273. Train Acc 0.8198. Test Acc 0.7988.\n",
      "Epoch 6. Train Loss 0.4818. Train Acc 0.8365. Test Acc 0.7558.\n",
      "Epoch 7. Train Loss 0.4458. Train Acc 0.8466. Test Acc 0.7710.\n",
      "Epoch 8. Train Loss 0.4164. Train Acc 0.8575. Test Acc 0.8203.\n",
      "Epoch 9. Train Loss 0.3987. Train Acc 0.8646. Test Acc 0.8012.\n",
      "Epoch 10. Train Loss 0.3775. Train Acc 0.8711. Test Acc 0.8291.\n",
      "Epoch 11. Train Loss 0.3589. Train Acc 0.8775. Test Acc 0.8442.\n",
      "Epoch 12. Train Loss 0.3428. Train Acc 0.8827. Test Acc 0.7830.\n",
      "Epoch 13. Train Loss 0.3343. Train Acc 0.8867. Test Acc 0.8191.\n",
      "Epoch 14. Train Loss 0.3161. Train Acc 0.8926. Test Acc 0.8429.\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    print(\"Batch size: %d\"%(batch_size))\n",
    "    train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "    model=ResNet(ResidualBlock,[3,3,2]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01*(batch_size/32),momentum=0.9, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=50)\n",
    "    for i in range(epochs):\n",
    "        train_loss, train_acc=train(model)\n",
    "        test_acc=test(model)\n",
    "        print(\"Epoch %d. Train Loss %.4f. Train Acc %.4f. Test Acc %.4f.\"%(i,train_loss,train_acc,test_acc))\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e26f8ec-6cc9-4b7d-973c-84525f91f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 128\n",
      "Epoch 0. Train Loss 1.5500. Train Acc 0.4239. Test Acc 0.5412.\n",
      "Epoch 1. Train Loss 1.0380. Train Acc 0.6266. Test Acc 0.6440.\n",
      "Epoch 2. Train Loss 0.8067. Train Acc 0.7174. Test Acc 0.6652.\n",
      "Epoch 3. Train Loss 0.6657. Train Acc 0.7677. Test Acc 0.7159.\n",
      "Epoch 4. Train Loss 0.5781. Train Acc 0.8008. Test Acc 0.7537.\n",
      "Epoch 5. Train Loss 0.5194. Train Acc 0.8194. Test Acc 0.8079.\n",
      "Epoch 6. Train Loss 0.4855. Train Acc 0.8328. Test Acc 0.7793.\n",
      "Epoch 7. Train Loss 0.4423. Train Acc 0.8481. Test Acc 0.8067.\n",
      "Epoch 8. Train Loss 0.4104. Train Acc 0.8601. Test Acc 0.7995.\n",
      "Epoch 9. Train Loss 0.3903. Train Acc 0.8671. Test Acc 0.8343.\n",
      "Epoch 10. Train Loss 0.3714. Train Acc 0.8735. Test Acc 0.8535.\n",
      "Epoch 11. Train Loss 0.3595. Train Acc 0.8778. Test Acc 0.8358.\n",
      "Epoch 12. Train Loss 0.3418. Train Acc 0.8851. Test Acc 0.8424.\n",
      "Epoch 13. Train Loss 0.3324. Train Acc 0.8876. Test Acc 0.8488.\n",
      "Epoch 14. Train Loss 0.3185. Train Acc 0.8915. Test Acc 0.8685.\n",
      "Epoch 15. Train Loss 0.3034. Train Acc 0.8965. Test Acc 0.8445.\n",
      "Epoch 16. Train Loss 0.2900. Train Acc 0.8998. Test Acc 0.8589.\n",
      "Epoch 17. Train Loss 0.2727. Train Acc 0.9077. Test Acc 0.8531.\n",
      "Epoch 18. Train Loss 0.2702. Train Acc 0.9087. Test Acc 0.8207.\n",
      "Epoch 19. Train Loss 0.2530. Train Acc 0.9130. Test Acc 0.8561.\n",
      "Epoch 20. Train Loss 0.2416. Train Acc 0.9182. Test Acc 0.8398.\n",
      "Epoch 21. Train Loss 0.2266. Train Acc 0.9234. Test Acc 0.8520.\n",
      "Epoch 22. Train Loss 0.2157. Train Acc 0.9267. Test Acc 0.8838.\n",
      "Epoch 23. Train Loss 0.2067. Train Acc 0.9304. Test Acc 0.8871.\n",
      "Epoch 24. Train Loss 0.1911. Train Acc 0.9353. Test Acc 0.8630.\n",
      "Epoch 25. Train Loss 0.1785. Train Acc 0.9404. Test Acc 0.8709.\n",
      "Epoch 26. Train Loss 0.1672. Train Acc 0.9442. Test Acc 0.8733.\n",
      "Epoch 27. Train Loss 0.1545. Train Acc 0.9479. Test Acc 0.8871.\n",
      "Epoch 28. Train Loss 0.1405. Train Acc 0.9541. Test Acc 0.8990.\n",
      "Epoch 29. Train Loss 0.1306. Train Acc 0.9585. Test Acc 0.8755.\n",
      "Epoch 30. Train Loss 0.1164. Train Acc 0.9621. Test Acc 0.8920.\n",
      "Epoch 31. Train Loss 0.1042. Train Acc 0.9656. Test Acc 0.9106.\n",
      "Epoch 32. Train Loss 0.0886. Train Acc 0.9715. Test Acc 0.9115.\n",
      "Epoch 33. Train Loss 0.0805. Train Acc 0.9754. Test Acc 0.9228.\n",
      "Epoch 34. Train Loss 0.0631. Train Acc 0.9813. Test Acc 0.9295.\n",
      "Epoch 35. Train Loss 0.0486. Train Acc 0.9866. Test Acc 0.9241.\n",
      "Epoch 36. Train Loss 0.0381. Train Acc 0.9902. Test Acc 0.9330.\n",
      "Epoch 37. Train Loss 0.0314. Train Acc 0.9925. Test Acc 0.9273.\n",
      "Epoch 38. Train Loss 0.0224. Train Acc 0.9958. Test Acc 0.9425.\n",
      "Epoch 39. Train Loss 0.0171. Train Acc 0.9973. Test Acc 0.9391.\n",
      "Epoch 40. Train Loss 0.0137. Train Acc 0.9983. Test Acc 0.9451.\n",
      "Epoch 41. Train Loss 0.0117. Train Acc 0.9989. Test Acc 0.9451.\n",
      "Epoch 42. Train Loss 0.0105. Train Acc 0.9990. Test Acc 0.9465.\n",
      "Epoch 43. Train Loss 0.0092. Train Acc 0.9993. Test Acc 0.9461.\n",
      "Epoch 44. Train Loss 0.0083. Train Acc 0.9994. Test Acc 0.9463.\n",
      "Epoch 45. Train Loss 0.0081. Train Acc 0.9995. Test Acc 0.9477.\n",
      "Epoch 46. Train Loss 0.0075. Train Acc 0.9997. Test Acc 0.9479.\n",
      "Epoch 47. Train Loss 0.0075. Train Acc 0.9996. Test Acc 0.9470.\n",
      "Epoch 48. Train Loss 0.0071. Train Acc 0.9998. Test Acc 0.9484.\n",
      "Epoch 49. Train Loss 0.0072. Train Acc 0.9998. Test Acc 0.9480.\n",
      "Batch size: 256\n",
      "Epoch 0. Train Loss 1.7512. Train Acc 0.3520. Test Acc 0.4253.\n",
      "Epoch 1. Train Loss 1.2726. Train Acc 0.5350. Test Acc 0.5500.\n",
      "Epoch 2. Train Loss 1.0048. Train Acc 0.6418. Test Acc 0.5504.\n",
      "Epoch 3. Train Loss 0.8446. Train Acc 0.7008. Test Acc 0.5588.\n",
      "Epoch 4. Train Loss 0.7159. Train Acc 0.7482. Test Acc 0.7016.\n",
      "Epoch 5. Train Loss 0.6224. Train Acc 0.7843. Test Acc 0.7377.\n",
      "Epoch 6. Train Loss 0.5521. Train Acc 0.8099. Test Acc 0.7671.\n",
      "Epoch 7. Train Loss 0.5033. Train Acc 0.8268. Test Acc 0.7461.\n",
      "Epoch 8. Train Loss 0.4643. Train Acc 0.8420. Test Acc 0.7729.\n",
      "Epoch 9. Train Loss 0.4337. Train Acc 0.8519. Test Acc 0.8202.\n",
      "Epoch 10. Train Loss 0.3994. Train Acc 0.8635. Test Acc 0.8215.\n",
      "Epoch 11. Train Loss 0.3813. Train Acc 0.8688. Test Acc 0.7788.\n",
      "Epoch 12. Train Loss 0.3663. Train Acc 0.8746. Test Acc 0.8098.\n",
      "Epoch 13. Train Loss 0.3528. Train Acc 0.8779. Test Acc 0.7901.\n",
      "Epoch 14. Train Loss 0.3303. Train Acc 0.8869. Test Acc 0.8125.\n",
      "Epoch 15. Train Loss 0.3223. Train Acc 0.8899. Test Acc 0.8321.\n",
      "Epoch 16. Train Loss 0.3047. Train Acc 0.8970. Test Acc 0.8295.\n",
      "Epoch 17. Train Loss 0.2888. Train Acc 0.9018. Test Acc 0.8416.\n",
      "Epoch 18. Train Loss 0.2818. Train Acc 0.9044. Test Acc 0.8229.\n",
      "Epoch 19. Train Loss 0.2616. Train Acc 0.9102. Test Acc 0.8423.\n",
      "Epoch 20. Train Loss 0.2449. Train Acc 0.9168. Test Acc 0.8518.\n",
      "Epoch 21. Train Loss 0.2383. Train Acc 0.9181. Test Acc 0.8473.\n",
      "Epoch 22. Train Loss 0.2214. Train Acc 0.9247. Test Acc 0.7970.\n",
      "Epoch 23. Train Loss 0.2125. Train Acc 0.9268. Test Acc 0.8600.\n",
      "Epoch 24. Train Loss 0.1981. Train Acc 0.9327. Test Acc 0.8692.\n",
      "Epoch 25. Train Loss 0.1833. Train Acc 0.9385. Test Acc 0.8465.\n",
      "Epoch 26. Train Loss 0.1781. Train Acc 0.9399. Test Acc 0.8923.\n",
      "Epoch 27. Train Loss 0.1595. Train Acc 0.9474. Test Acc 0.8737.\n",
      "Epoch 28. Train Loss 0.1451. Train Acc 0.9514. Test Acc 0.8897.\n",
      "Epoch 29. Train Loss 0.1310. Train Acc 0.9565. Test Acc 0.8999.\n",
      "Epoch 30. Train Loss 0.1182. Train Acc 0.9616. Test Acc 0.8886.\n",
      "Epoch 31. Train Loss 0.1096. Train Acc 0.9638. Test Acc 0.8919.\n",
      "Epoch 32. Train Loss 0.0904. Train Acc 0.9715. Test Acc 0.9186.\n",
      "Epoch 33. Train Loss 0.0695. Train Acc 0.9788. Test Acc 0.9146.\n",
      "Epoch 34. Train Loss 0.0679. Train Acc 0.9790. Test Acc 0.9260.\n",
      "Epoch 35. Train Loss 0.0563. Train Acc 0.9833. Test Acc 0.9103.\n",
      "Epoch 36. Train Loss 0.0397. Train Acc 0.9899. Test Acc 0.9336.\n",
      "Epoch 37. Train Loss 0.0297. Train Acc 0.9932. Test Acc 0.9352.\n",
      "Epoch 38. Train Loss 0.0219. Train Acc 0.9959. Test Acc 0.9387.\n",
      "Epoch 39. Train Loss 0.0165. Train Acc 0.9975. Test Acc 0.9392.\n",
      "Epoch 40. Train Loss 0.0126. Train Acc 0.9985. Test Acc 0.9438.\n",
      "Epoch 41. Train Loss 0.0113. Train Acc 0.9988. Test Acc 0.9439.\n",
      "Epoch 42. Train Loss 0.0098. Train Acc 0.9991. Test Acc 0.9449.\n",
      "Epoch 43. Train Loss 0.0083. Train Acc 0.9994. Test Acc 0.9452.\n",
      "Epoch 44. Train Loss 0.0078. Train Acc 0.9996. Test Acc 0.9465.\n",
      "Epoch 45. Train Loss 0.0073. Train Acc 0.9996. Test Acc 0.9464.\n",
      "Epoch 46. Train Loss 0.0070. Train Acc 0.9997. Test Acc 0.9466.\n",
      "Epoch 47. Train Loss 0.0068. Train Acc 0.9997. Test Acc 0.9468.\n",
      "Epoch 48. Train Loss 0.0066. Train Acc 0.9999. Test Acc 0.9469.\n",
      "Epoch 49. Train Loss 0.0067. Train Acc 0.9998. Test Acc 0.9466.\n"
     ]
    }
   ],
   "source": [
    "batch_sizes=[128,256]\n",
    "for batch_size in batch_sizes:\n",
    "    print(\"Batch size: %d\"%(batch_size))\n",
    "    train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "    model=ResNet(ResidualBlock,[3,3,2]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01*(batch_size/32),momentum=0.9, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=50)\n",
    "    for i in range(epochs):\n",
    "        train_loss, train_acc=train(model)\n",
    "        test_acc=test(model)\n",
    "        print(\"Epoch %d. Train Loss %.4f. Train Acc %.4f. Test Acc %.4f.\"%(i,train_loss,train_acc,test_acc))\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b1966-692d-4f47-8c95-03b147a7d175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
